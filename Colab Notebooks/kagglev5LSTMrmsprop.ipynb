{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kagglev5LSTMrmsprop.ipynb","provenance":[{"file_id":"18NW5x3bNxlpbUUFi3NDNdQcJRdou76Yp","timestamp":1600815148809},{"file_id":"1OVuLTfpZsGlh0o754Bh14akEwSxRm2lp","timestamp":1600814573458},{"file_id":"1JTFH4KZMS8z9UfZlXh6JF275nKaQAjB3","timestamp":1600813371274},{"file_id":"1Pvw6VV-7d_rMg05b6_HBVI6j6DE7cJ0R","timestamp":1600812883058}],"mount_file_id":"1Pvw6VV-7d_rMg05b6_HBVI6j6DE7cJ0R","authorship_tag":"ABX9TyMEYfFpLR6Xg1zfywiu9ci/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OXEpvGDeLorS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815392080,"user_tz":240,"elapsed":2063,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"moz5YNO-DS8E","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815744776,"user_tz":240,"elapsed":484,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["from tensorflow.keras.layers import Bidirectional"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"spXCVLbiPb_T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815409881,"user_tz":240,"elapsed":19854,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"ec6e97e6-d838-46f3-d3cf-a44ad7298f77"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WU3tuwvEPFN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815415978,"user_tz":240,"elapsed":3570,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["train=np.load(\"./drive/My Drive/audio_train.npy\")\n","test=np.load(\"./drive/My Drive/audio_test.npy\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrMyv-VGQsZI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815417046,"user_tz":240,"elapsed":3334,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["train_labels=pd.read_csv(\"./drive/My Drive/labels_train.csv\")\n","sample_submission=pd.read_csv(\"./drive/My Drive/sample_submission.csv\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWEfnFFv38Ce","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1600815417567,"user_tz":240,"elapsed":355,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"8bbf9fd5-a101-433e-f420-f3f202506b6c"},"source":["train_labels"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>937</th>\n","      <td>937</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>938</th>\n","      <td>938</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>939</th>\n","      <td>939</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>940</th>\n","      <td>940</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>941</th>\n","      <td>941</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>942 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      id  label\n","0      0      5\n","1      1      1\n","2      2      1\n","3      3      0\n","4      4      9\n","..   ...    ...\n","937  937      9\n","938  938      1\n","939  939      1\n","940  940      5\n","941  941      9\n","\n","[942 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"eAgGe4FB3vVF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815419609,"user_tz":240,"elapsed":798,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["label = list(train_labels['label'])\n","\n","y_train = np.empty([len(train),1])\n","for i in range(len(label)):\n","  y_train[i] = label[i]\n","y_train = np.array(y_train, dtype='uint8')\n","\n","num_classes = 10\n","y_train = keras.utils.to_categorical(y_train, num_classes)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y69mD4x84wHv","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbOkr8ZjRIGW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1600815421069,"user_tz":240,"elapsed":657,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"3be4de36-f56c-4c82-fe23-5dedbd618767"},"source":["plt.plot(train[2])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f9723a495c0>]"]},"metadata":{"tags":[]},"execution_count":7},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"tlE3mQg1RdPD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815422267,"user_tz":240,"elapsed":389,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"52187b44-d848-4990-c3ad-8e01004394bf"},"source":["print(train_labels.label.unique())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[5 1 0 9 4 6 7 3 8]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vRzPmQw0RifR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815424319,"user_tz":240,"elapsed":414,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"1e0bcbd6-b77b-49e1-b238-bdeaff7ca737"},"source":["print(sample_submission.label.unique())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[ 1  6  3  7  4  8  9  5  2  0 10]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dcaYdqDbb8Ld","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815425473,"user_tz":240,"elapsed":397,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"2e5f8b44-9333-4b85-9300-e232a43cd822"},"source":["print(np.shape(test)[1])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["30000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qn4AvffyXdsZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815427324,"user_tz":240,"elapsed":394,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["verbose, epochs, batch_size = 0, 10, 32"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOhYnVt3Xf73","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600815428722,"user_tz":240,"elapsed":633,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["n_timesteps, n_features, n_outputs = train.shape[0], train.shape[1], train_labels.shape[0]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJDhLSsWcTQx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815429363,"user_tz":240,"elapsed":528,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"7bc4785c-d318-4feb-952c-012911489e45"},"source":["n_timesteps"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["942"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"J-MIc-NZvFe2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815430549,"user_tz":240,"elapsed":439,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"4eedb2da-b847-4f20-dfd3-79720ec32b31"},"source":["train.shape[0],train.shape[1]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(942, 30000)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"iTIGHNr5vOjm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815431595,"user_tz":240,"elapsed":436,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"0b2253b4-05eb-4de4-f8b6-89e3a445e03c"},"source":["train1=np.reshape(train,(train.shape[0],500,60))\n","train1.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(942, 500, 60)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"qHA7Ltoa6is5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815433373,"user_tz":240,"elapsed":730,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"afef0453-2a8f-4219-ec09-4117cd464b8a"},"source":["test1=np.reshape(test,(test.shape[0],500,60))\n","test1.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(558, 500, 60)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"vUfS-bu81y2Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815434274,"user_tz":240,"elapsed":727,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"d8a53efb-656e-47b1-9339-992263a3fe73"},"source":["train_labels.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(942, 2)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"X287OlDu5NIP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600815435407,"user_tz":240,"elapsed":380,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"eacd45c6-8505-4415-d62e-0775267dbe5d"},"source":["train.shape[1]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30000"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"lIewOzrJEDq4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600816082353,"user_tz":240,"elapsed":533,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["from keras.layers import Input, LSTM, Dense, TimeDistributed, Activation, BatchNormalization, Dropout, Bidirectional, ELU\n","from keras.models import Sequential\n","from keras.utils import Sequence\n","from keras.layers import LSTM"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4JJZbgUFjGH","colab_type":"text"},"source":["NO"]},{"cell_type":"code","metadata":{"id":"_RjxLl9mU79f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600816084375,"user_tz":240,"elapsed":985,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["\n","# Neural network model\n","input_shape=(500,60)\n","#optimizer = adam(0.005, beta_1=0.1, beta_2=0.001, amsgrad=True)\n","n_classes = 80\n","\n","model = models.Sequential()\n","model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=input_shape))\n","model.add(Dense(500))\n","model.add(Dropout(0.2))\n","model.add(Dense(100))\n","model.add(ELU())\n","model.add(Dropout(0.2)) \n","model.add(Dense(10, activation='softmax'))\n","\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVaWtLHuFit1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600816340187,"user_tz":240,"elapsed":1328,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["model = models.Sequential()\n","model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(500,60)))\n","model.add(Bidirectional(LSTM(60)))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWZT-7S5Y0Ii","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1600816341965,"user_tz":240,"elapsed":426,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"842c93ab-0484-4185-9d52-5866507c80a2"},"source":["model.summary()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_3 (Bidirection (None, 500, 20)           5680      \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 120)               38880     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                1210      \n","_________________________________________________________________\n","activation (Activation)      (None, 10)                0         \n","=================================================================\n","Total params: 45,770\n","Trainable params: 45,770\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TdE8eVquFvVW","colab_type":"text"},"source":["no"]},{"cell_type":"code","metadata":{"id":"JzDeXnN9ZyUE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":918},"executionInfo":{"status":"error","timestamp":1600816113389,"user_tz":240,"elapsed":1369,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"ba07c5b0-c290-440e-b7c2-b3067d9ba1e3"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n","              metrics=['accuracy'])\n","\n","history = model.fit(train1, y_train, epochs=500)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-1c29743bbb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 10) and (None, 500, 10) are incompatible\n"]}]},{"cell_type":"code","metadata":{"id":"yk1rvQ1iFxqa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600817402191,"user_tz":240,"elapsed":1015204,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"b2ef8577-0a6d-4219-ea5e-39414339e85f"},"source":["model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","history = model.fit(train1, y_train, epochs=500)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","30/30 [==============================] - 2s 66ms/step - loss: 2.2273 - accuracy: 0.1412\n","Epoch 2/500\n","30/30 [==============================] - 2s 63ms/step - loss: 2.0981 - accuracy: 0.1953\n","Epoch 3/500\n","30/30 [==============================] - 2s 62ms/step - loss: 2.0304 - accuracy: 0.2229\n","Epoch 4/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.9448 - accuracy: 0.2696\n","Epoch 5/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.8827 - accuracy: 0.2834\n","Epoch 6/500\n","30/30 [==============================] - 2s 66ms/step - loss: 1.8460 - accuracy: 0.3068\n","Epoch 7/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.7586 - accuracy: 0.3588\n","Epoch 8/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.6991 - accuracy: 0.3758\n","Epoch 9/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.6006 - accuracy: 0.4076\n","Epoch 10/500\n","30/30 [==============================] - 2s 66ms/step - loss: 1.5806 - accuracy: 0.4161\n","Epoch 11/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.5748 - accuracy: 0.4416\n","Epoch 12/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.5209 - accuracy: 0.4533\n","Epoch 13/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.4488 - accuracy: 0.5032\n","Epoch 14/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.4035 - accuracy: 0.5191\n","Epoch 15/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.4149 - accuracy: 0.5064\n","Epoch 16/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.5205 - accuracy: 0.4777\n","Epoch 17/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.3423 - accuracy: 0.5340\n","Epoch 18/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.3611 - accuracy: 0.5191\n","Epoch 19/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.3272 - accuracy: 0.5318\n","Epoch 20/500\n","30/30 [==============================] - 2s 68ms/step - loss: 1.2918 - accuracy: 0.5414\n","Epoch 21/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.2669 - accuracy: 0.5488\n","Epoch 22/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.2241 - accuracy: 0.5732\n","Epoch 23/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.2281 - accuracy: 0.5467\n","Epoch 24/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.4141 - accuracy: 0.5032\n","Epoch 25/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.1655 - accuracy: 0.5701\n","Epoch 26/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.1878 - accuracy: 0.5626\n","Epoch 27/500\n","30/30 [==============================] - 2s 65ms/step - loss: 1.1417 - accuracy: 0.5860\n","Epoch 28/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.1302 - accuracy: 0.5945\n","Epoch 29/500\n","30/30 [==============================] - 2s 63ms/step - loss: 1.1195 - accuracy: 0.5870\n","Epoch 30/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.0717 - accuracy: 0.5955\n","Epoch 31/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.2831 - accuracy: 0.5520\n","Epoch 32/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.2284 - accuracy: 0.5594\n","Epoch 33/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.0707 - accuracy: 0.5902\n","Epoch 34/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.0519 - accuracy: 0.5998\n","Epoch 35/500\n","30/30 [==============================] - 2s 63ms/step - loss: 1.0441 - accuracy: 0.6157\n","Epoch 36/500\n","30/30 [==============================] - 2s 66ms/step - loss: 1.0143 - accuracy: 0.6200\n","Epoch 37/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.9849 - accuracy: 0.6412\n","Epoch 38/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.9684 - accuracy: 0.6338\n","Epoch 39/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.9688 - accuracy: 0.6369\n","Epoch 40/500\n","30/30 [==============================] - 2s 63ms/step - loss: 1.0361 - accuracy: 0.6274\n","Epoch 41/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.9300 - accuracy: 0.6486\n","Epoch 42/500\n","30/30 [==============================] - 2s 63ms/step - loss: 1.0385 - accuracy: 0.6348\n","Epoch 43/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.9613 - accuracy: 0.6444\n","Epoch 44/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.9269 - accuracy: 0.6592\n","Epoch 45/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.9778 - accuracy: 0.6338\n","Epoch 46/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.9038 - accuracy: 0.6709\n","Epoch 47/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.9284 - accuracy: 0.6550\n","Epoch 48/500\n","30/30 [==============================] - 2s 62ms/step - loss: 1.0005 - accuracy: 0.6423\n","Epoch 49/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8814 - accuracy: 0.6667\n","Epoch 50/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.8722 - accuracy: 0.6720\n","Epoch 51/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8733 - accuracy: 0.6688\n","Epoch 52/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8913 - accuracy: 0.6614\n","Epoch 53/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8500 - accuracy: 0.6932\n","Epoch 54/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.8802 - accuracy: 0.6645\n","Epoch 55/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.9241 - accuracy: 0.6592\n","Epoch 56/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8879 - accuracy: 0.6656\n","Epoch 57/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8535 - accuracy: 0.6805\n","Epoch 58/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8709 - accuracy: 0.6667\n","Epoch 59/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8451 - accuracy: 0.6837\n","Epoch 60/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8484 - accuracy: 0.6773\n","Epoch 61/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.8268 - accuracy: 0.6730\n","Epoch 62/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8922 - accuracy: 0.6645\n","Epoch 63/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.7952 - accuracy: 0.6847\n","Epoch 64/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8183 - accuracy: 0.6890\n","Epoch 65/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.8483 - accuracy: 0.6794\n","Epoch 66/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8106 - accuracy: 0.6879\n","Epoch 67/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8850 - accuracy: 0.6741\n","Epoch 68/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7905 - accuracy: 0.6964\n","Epoch 69/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8217 - accuracy: 0.6826\n","Epoch 70/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.8040 - accuracy: 0.6847\n","Epoch 71/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8043 - accuracy: 0.6996\n","Epoch 72/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8778 - accuracy: 0.6794\n","Epoch 73/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7769 - accuracy: 0.7017\n","Epoch 74/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8160 - accuracy: 0.6890\n","Epoch 75/500\n","30/30 [==============================] - 2s 61ms/step - loss: 0.8332 - accuracy: 0.6858\n","Epoch 76/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.8006 - accuracy: 0.6794\n","Epoch 77/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8267 - accuracy: 0.6975\n","Epoch 78/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8350 - accuracy: 0.6911\n","Epoch 79/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7690 - accuracy: 0.7134\n","Epoch 80/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7798 - accuracy: 0.7176\n","Epoch 81/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7793 - accuracy: 0.6996\n","Epoch 82/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.7663 - accuracy: 0.7006\n","Epoch 83/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7717 - accuracy: 0.6985\n","Epoch 84/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7625 - accuracy: 0.7059\n","Epoch 85/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7618 - accuracy: 0.7134\n","Epoch 86/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7478 - accuracy: 0.7187\n","Epoch 87/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.7613 - accuracy: 0.7081\n","Epoch 88/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7524 - accuracy: 0.7102\n","Epoch 89/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7597 - accuracy: 0.7006\n","Epoch 90/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.7508 - accuracy: 0.7155\n","Epoch 91/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7399 - accuracy: 0.7166\n","Epoch 92/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.7386 - accuracy: 0.7229\n","Epoch 93/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7254 - accuracy: 0.7251\n","Epoch 94/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7794 - accuracy: 0.7091\n","Epoch 95/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7402 - accuracy: 0.7134\n","Epoch 96/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7532 - accuracy: 0.7282\n","Epoch 97/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7347 - accuracy: 0.7208\n","Epoch 98/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7113 - accuracy: 0.7282\n","Epoch 99/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7110 - accuracy: 0.7357\n","Epoch 100/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7369 - accuracy: 0.7176\n","Epoch 101/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7034 - accuracy: 0.7367\n","Epoch 102/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7099 - accuracy: 0.7282\n","Epoch 103/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7331 - accuracy: 0.7208\n","Epoch 104/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7113 - accuracy: 0.7166\n","Epoch 105/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.7305 - accuracy: 0.7325\n","Epoch 106/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7298 - accuracy: 0.7102\n","Epoch 107/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7057 - accuracy: 0.7399\n","Epoch 108/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.7206 - accuracy: 0.7346\n","Epoch 109/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7043 - accuracy: 0.7378\n","Epoch 110/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6850 - accuracy: 0.7452\n","Epoch 111/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7074 - accuracy: 0.7367\n","Epoch 112/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.6969 - accuracy: 0.7314\n","Epoch 113/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6842 - accuracy: 0.7442\n","Epoch 114/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6677 - accuracy: 0.7505\n","Epoch 115/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6888 - accuracy: 0.7399\n","Epoch 116/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.8147 - accuracy: 0.7314\n","Epoch 117/500\n","30/30 [==============================] - 2s 61ms/step - loss: 0.6815 - accuracy: 0.7410\n","Epoch 118/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.6853 - accuracy: 0.7590\n","Epoch 119/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6715 - accuracy: 0.7452\n","Epoch 120/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.6688 - accuracy: 0.7505\n","Epoch 121/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6883 - accuracy: 0.7410\n","Epoch 122/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6537 - accuracy: 0.7622\n","Epoch 123/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.6430 - accuracy: 0.7643\n","Epoch 124/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.6589 - accuracy: 0.7590\n","Epoch 125/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6407 - accuracy: 0.7622\n","Epoch 126/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7248 - accuracy: 0.7420\n","Epoch 127/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.6298 - accuracy: 0.7611\n","Epoch 128/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7327 - accuracy: 0.7325\n","Epoch 129/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.7120 - accuracy: 0.7537\n","Epoch 130/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.6207 - accuracy: 0.7718\n","Epoch 131/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.5955 - accuracy: 0.7834\n","Epoch 132/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6595 - accuracy: 0.7601\n","Epoch 133/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6259 - accuracy: 0.7643\n","Epoch 134/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6623 - accuracy: 0.7686\n","Epoch 135/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6512 - accuracy: 0.7580\n","Epoch 136/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.6332 - accuracy: 0.7696\n","Epoch 137/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6016 - accuracy: 0.7792\n","Epoch 138/500\n","30/30 [==============================] - 2s 63ms/step - loss: 1.3868 - accuracy: 0.6582\n","Epoch 139/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.9973 - accuracy: 0.6529\n","Epoch 140/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8480 - accuracy: 0.7113\n","Epoch 141/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.6620 - accuracy: 0.7654\n","Epoch 142/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6330 - accuracy: 0.7665\n","Epoch 143/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.6874 - accuracy: 0.7548\n","Epoch 144/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6089 - accuracy: 0.7749\n","Epoch 145/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.5930 - accuracy: 0.7803\n","Epoch 146/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.7042 - accuracy: 0.7824\n","Epoch 147/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.5840 - accuracy: 0.7887\n","Epoch 148/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.5793 - accuracy: 0.7919\n","Epoch 149/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.9021 - accuracy: 0.7229\n","Epoch 150/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.8556 - accuracy: 0.6847\n","Epoch 151/500\n","30/30 [==============================] - 2s 70ms/step - loss: 0.6980 - accuracy: 0.7442\n","Epoch 152/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7030 - accuracy: 0.7527\n","Epoch 153/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.7511 - accuracy: 0.7325\n","Epoch 154/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6349 - accuracy: 0.7611\n","Epoch 155/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.6232 - accuracy: 0.7813\n","Epoch 156/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.5768 - accuracy: 0.7845\n","Epoch 157/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.5756 - accuracy: 0.7824\n","Epoch 158/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6891 - accuracy: 0.7643\n","Epoch 159/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.6394 - accuracy: 0.7622\n","Epoch 160/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.5694 - accuracy: 0.7930\n","Epoch 161/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.5595 - accuracy: 0.7941\n","Epoch 162/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.5357 - accuracy: 0.7972\n","Epoch 163/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.5812 - accuracy: 0.7972\n","Epoch 164/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.5713 - accuracy: 0.8047\n","Epoch 165/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.6189 - accuracy: 0.7803\n","Epoch 166/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6699 - accuracy: 0.7622\n","Epoch 167/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.5384 - accuracy: 0.8015\n","Epoch 168/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.5324 - accuracy: 0.8110\n","Epoch 169/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.6412 - accuracy: 0.7590\n","Epoch 170/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.5967 - accuracy: 0.7962\n","Epoch 171/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.5231 - accuracy: 0.7919\n","Epoch 172/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.5587 - accuracy: 0.8004\n","Epoch 173/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.5183 - accuracy: 0.8057\n","Epoch 174/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.5122 - accuracy: 0.8068\n","Epoch 175/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8067 - accuracy: 0.7824\n","Epoch 176/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.5346 - accuracy: 0.8068\n","Epoch 177/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.5860 - accuracy: 0.8025\n","Epoch 178/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.5204 - accuracy: 0.8079\n","Epoch 179/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4843 - accuracy: 0.8195\n","Epoch 180/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.5417 - accuracy: 0.8025\n","Epoch 181/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4778 - accuracy: 0.8174\n","Epoch 182/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.4605 - accuracy: 0.8238\n","Epoch 183/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.9837 - accuracy: 0.7452\n","Epoch 184/500\n","30/30 [==============================] - 2s 64ms/step - loss: 1.1384 - accuracy: 0.6656\n","Epoch 185/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8457 - accuracy: 0.7219\n","Epoch 186/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.7683 - accuracy: 0.7537\n","Epoch 187/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.5286 - accuracy: 0.8015\n","Epoch 188/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4759 - accuracy: 0.8259\n","Epoch 189/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4941 - accuracy: 0.8248\n","Epoch 190/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.4775 - accuracy: 0.8217\n","Epoch 191/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.4735 - accuracy: 0.8217\n","Epoch 192/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4498 - accuracy: 0.8280\n","Epoch 193/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4440 - accuracy: 0.8408\n","Epoch 194/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4767 - accuracy: 0.8301\n","Epoch 195/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4400 - accuracy: 0.8461\n","Epoch 196/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.8355 - accuracy: 0.7442\n","Epoch 197/500\n","30/30 [==============================] - 2s 70ms/step - loss: 0.6912 - accuracy: 0.7516\n","Epoch 198/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.5440 - accuracy: 0.8121\n","Epoch 199/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4415 - accuracy: 0.8471\n","Epoch 200/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.4438 - accuracy: 0.8418\n","Epoch 201/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4133 - accuracy: 0.8641\n","Epoch 202/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4301 - accuracy: 0.8429\n","Epoch 203/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.4198 - accuracy: 0.8461\n","Epoch 204/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6090 - accuracy: 0.8025\n","Epoch 205/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.5862 - accuracy: 0.7919\n","Epoch 206/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4259 - accuracy: 0.8418\n","Epoch 207/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3976 - accuracy: 0.8439\n","Epoch 208/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4925 - accuracy: 0.8376\n","Epoch 209/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4096 - accuracy: 0.8556\n","Epoch 210/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4037 - accuracy: 0.8546\n","Epoch 211/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4174 - accuracy: 0.8450\n","Epoch 212/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3704 - accuracy: 0.8673\n","Epoch 213/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3886 - accuracy: 0.8577\n","Epoch 214/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4226 - accuracy: 0.8588\n","Epoch 215/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3732 - accuracy: 0.8684\n","Epoch 216/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3664 - accuracy: 0.8641\n","Epoch 217/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3808 - accuracy: 0.8577\n","Epoch 218/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.3996 - accuracy: 0.8524\n","Epoch 219/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3770 - accuracy: 0.8662\n","Epoch 220/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.0514 - accuracy: 0.7420\n","Epoch 221/500\n","30/30 [==============================] - 2s 67ms/step - loss: 1.1299 - accuracy: 0.7187\n","Epoch 222/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8381 - accuracy: 0.7399\n","Epoch 223/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.6477 - accuracy: 0.7887\n","Epoch 224/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.8111 - accuracy: 0.7590\n","Epoch 225/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.6046 - accuracy: 0.7919\n","Epoch 226/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.4914 - accuracy: 0.8132\n","Epoch 227/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.4961 - accuracy: 0.8270\n","Epoch 228/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3967 - accuracy: 0.8556\n","Epoch 229/500\n","30/30 [==============================] - 2s 70ms/step - loss: 0.4328 - accuracy: 0.8450\n","Epoch 230/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3833 - accuracy: 0.8662\n","Epoch 231/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3738 - accuracy: 0.8684\n","Epoch 232/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3950 - accuracy: 0.8673\n","Epoch 233/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3771 - accuracy: 0.8684\n","Epoch 234/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3326 - accuracy: 0.8843\n","Epoch 235/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.3557 - accuracy: 0.8747\n","Epoch 236/500\n","30/30 [==============================] - 2s 61ms/step - loss: 0.3741 - accuracy: 0.8673\n","Epoch 237/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.3499 - accuracy: 0.8726\n","Epoch 238/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3467 - accuracy: 0.8662\n","Epoch 239/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3693 - accuracy: 0.8609\n","Epoch 240/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.5311 - accuracy: 0.8227\n","Epoch 241/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3621 - accuracy: 0.8694\n","Epoch 242/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3448 - accuracy: 0.8726\n","Epoch 243/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3067 - accuracy: 0.8822\n","Epoch 244/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3890 - accuracy: 0.8577\n","Epoch 245/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.3597 - accuracy: 0.8769\n","Epoch 246/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3388 - accuracy: 0.8811\n","Epoch 247/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.3806 - accuracy: 0.8652\n","Epoch 248/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3293 - accuracy: 0.8758\n","Epoch 249/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3061 - accuracy: 0.8896\n","Epoch 250/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3516 - accuracy: 0.8769\n","Epoch 251/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3554 - accuracy: 0.8705\n","Epoch 252/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2929 - accuracy: 0.8970\n","Epoch 253/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.3443 - accuracy: 0.8673\n","Epoch 254/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3334 - accuracy: 0.8843\n","Epoch 255/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.3131 - accuracy: 0.8854\n","Epoch 256/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.3536 - accuracy: 0.8747\n","Epoch 257/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2971 - accuracy: 0.8917\n","Epoch 258/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3106 - accuracy: 0.8907\n","Epoch 259/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3037 - accuracy: 0.8864\n","Epoch 260/500\n","30/30 [==============================] - 2s 72ms/step - loss: 0.3250 - accuracy: 0.8917\n","Epoch 261/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2887 - accuracy: 0.9023\n","Epoch 262/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2777 - accuracy: 0.9076\n","Epoch 263/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3219 - accuracy: 0.8737\n","Epoch 264/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3198 - accuracy: 0.8896\n","Epoch 265/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2859 - accuracy: 0.9023\n","Epoch 266/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2943 - accuracy: 0.8938\n","Epoch 267/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2809 - accuracy: 0.8938\n","Epoch 268/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3223 - accuracy: 0.8864\n","Epoch 269/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.2815 - accuracy: 0.8949\n","Epoch 270/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3233 - accuracy: 0.8885\n","Epoch 271/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2841 - accuracy: 0.8949\n","Epoch 272/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2759 - accuracy: 0.8981\n","Epoch 273/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2991 - accuracy: 0.8938\n","Epoch 274/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2738 - accuracy: 0.8949\n","Epoch 275/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2775 - accuracy: 0.9066\n","Epoch 276/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2782 - accuracy: 0.8970\n","Epoch 277/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.2809 - accuracy: 0.8970\n","Epoch 278/500\n","30/30 [==============================] - 2s 70ms/step - loss: 0.2858 - accuracy: 0.9002\n","Epoch 279/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4483 - accuracy: 0.8524\n","Epoch 280/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3228 - accuracy: 0.8907\n","Epoch 281/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.3721 - accuracy: 0.8694\n","Epoch 282/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2830 - accuracy: 0.8970\n","Epoch 283/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3158 - accuracy: 0.8822\n","Epoch 284/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2522 - accuracy: 0.9002\n","Epoch 285/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2615 - accuracy: 0.9108\n","Epoch 286/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2843 - accuracy: 0.9002\n","Epoch 287/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2621 - accuracy: 0.9045\n","Epoch 288/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2687 - accuracy: 0.9002\n","Epoch 289/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2579 - accuracy: 0.9076\n","Epoch 290/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3084 - accuracy: 0.8854\n","Epoch 291/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2606 - accuracy: 0.8992\n","Epoch 292/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2806 - accuracy: 0.8992\n","Epoch 293/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3250 - accuracy: 0.8949\n","Epoch 294/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2421 - accuracy: 0.9183\n","Epoch 295/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2844 - accuracy: 0.8992\n","Epoch 296/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.2572 - accuracy: 0.9013\n","Epoch 297/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2943 - accuracy: 0.8970\n","Epoch 298/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2632 - accuracy: 0.9045\n","Epoch 299/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.2686 - accuracy: 0.9002\n","Epoch 300/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2312 - accuracy: 0.9172\n","Epoch 301/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.5203 - accuracy: 0.8376\n","Epoch 302/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.4919 - accuracy: 0.8493\n","Epoch 303/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.4177 - accuracy: 0.8737\n","Epoch 304/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.2285 - accuracy: 0.9214\n","Epoch 305/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2406 - accuracy: 0.9214\n","Epoch 306/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2497 - accuracy: 0.9023\n","Epoch 307/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2424 - accuracy: 0.9130\n","Epoch 308/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2652 - accuracy: 0.8938\n","Epoch 309/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2521 - accuracy: 0.8970\n","Epoch 310/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.2442 - accuracy: 0.9087\n","Epoch 311/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2444 - accuracy: 0.9098\n","Epoch 312/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.4886 - accuracy: 0.8546\n","Epoch 313/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4539 - accuracy: 0.8461\n","Epoch 314/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.3016 - accuracy: 0.8928\n","Epoch 315/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2567 - accuracy: 0.9140\n","Epoch 316/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2146 - accuracy: 0.9236\n","Epoch 317/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2166 - accuracy: 0.9151\n","Epoch 318/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2292 - accuracy: 0.9119\n","Epoch 319/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3059 - accuracy: 0.8949\n","Epoch 320/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2515 - accuracy: 0.9151\n","Epoch 321/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2632 - accuracy: 0.9066\n","Epoch 322/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2813 - accuracy: 0.9023\n","Epoch 323/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2105 - accuracy: 0.9236\n","Epoch 324/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2406 - accuracy: 0.9108\n","Epoch 325/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2121 - accuracy: 0.9193\n","Epoch 326/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2303 - accuracy: 0.9130\n","Epoch 327/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2337 - accuracy: 0.9108\n","Epoch 328/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2163 - accuracy: 0.9193\n","Epoch 329/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2020 - accuracy: 0.9278\n","Epoch 330/500\n","30/30 [==============================] - 2s 73ms/step - loss: 0.2398 - accuracy: 0.9130\n","Epoch 331/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1845 - accuracy: 0.9278\n","Epoch 332/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2894 - accuracy: 0.9002\n","Epoch 333/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.9530 - accuracy: 0.8057\n","Epoch 334/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.4439 - accuracy: 0.8450\n","Epoch 335/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2307 - accuracy: 0.9161\n","Epoch 336/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2620 - accuracy: 0.9034\n","Epoch 337/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2415 - accuracy: 0.9098\n","Epoch 338/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1923 - accuracy: 0.9321\n","Epoch 339/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.2089 - accuracy: 0.9289\n","Epoch 340/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1993 - accuracy: 0.9246\n","Epoch 341/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.2292 - accuracy: 0.9204\n","Epoch 342/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.2227 - accuracy: 0.9214\n","Epoch 343/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1796 - accuracy: 0.9299\n","Epoch 344/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1976 - accuracy: 0.9321\n","Epoch 345/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1919 - accuracy: 0.9299\n","Epoch 346/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.2848 - accuracy: 0.9055\n","Epoch 347/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2354 - accuracy: 0.9172\n","Epoch 348/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2120 - accuracy: 0.9236\n","Epoch 349/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1985 - accuracy: 0.9310\n","Epoch 350/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1888 - accuracy: 0.9352\n","Epoch 351/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1943 - accuracy: 0.9246\n","Epoch 352/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2030 - accuracy: 0.9246\n","Epoch 353/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2673 - accuracy: 0.9130\n","Epoch 354/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1623 - accuracy: 0.9416\n","Epoch 355/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2256 - accuracy: 0.9172\n","Epoch 356/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1808 - accuracy: 0.9331\n","Epoch 357/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1826 - accuracy: 0.9374\n","Epoch 358/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1843 - accuracy: 0.9384\n","Epoch 359/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1926 - accuracy: 0.9331\n","Epoch 360/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2165 - accuracy: 0.9204\n","Epoch 361/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1444 - accuracy: 0.9490\n","Epoch 362/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1796 - accuracy: 0.9374\n","Epoch 363/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1911 - accuracy: 0.9310\n","Epoch 364/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1904 - accuracy: 0.9278\n","Epoch 365/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.6068 - accuracy: 0.8439\n","Epoch 366/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1698 - accuracy: 0.9427\n","Epoch 367/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.2096 - accuracy: 0.9321\n","Epoch 368/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1805 - accuracy: 0.9363\n","Epoch 369/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1518 - accuracy: 0.9437\n","Epoch 370/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1581 - accuracy: 0.9416\n","Epoch 371/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1607 - accuracy: 0.9427\n","Epoch 372/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1827 - accuracy: 0.9321\n","Epoch 373/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1327 - accuracy: 0.9554\n","Epoch 374/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1662 - accuracy: 0.9384\n","Epoch 375/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.3445 - accuracy: 0.9193\n","Epoch 376/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.7532 - accuracy: 0.8015\n","Epoch 377/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.8045 - accuracy: 0.7707\n","Epoch 378/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.6008 - accuracy: 0.7972\n","Epoch 379/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3711 - accuracy: 0.8779\n","Epoch 380/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2288 - accuracy: 0.9161\n","Epoch 381/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1959 - accuracy: 0.9331\n","Epoch 382/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1840 - accuracy: 0.9363\n","Epoch 383/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1433 - accuracy: 0.9533\n","Epoch 384/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.1367 - accuracy: 0.9512\n","Epoch 385/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.2138 - accuracy: 0.9374\n","Epoch 386/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1834 - accuracy: 0.9363\n","Epoch 387/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1516 - accuracy: 0.9480\n","Epoch 388/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1504 - accuracy: 0.9490\n","Epoch 389/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2061 - accuracy: 0.9352\n","Epoch 390/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1530 - accuracy: 0.9522\n","Epoch 391/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1827 - accuracy: 0.9374\n","Epoch 392/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1209 - accuracy: 0.9565\n","Epoch 393/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1551 - accuracy: 0.9342\n","Epoch 394/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1686 - accuracy: 0.9374\n","Epoch 395/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1469 - accuracy: 0.9586\n","Epoch 396/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1199 - accuracy: 0.9607\n","Epoch 397/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1801 - accuracy: 0.9374\n","Epoch 398/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1149 - accuracy: 0.9628\n","Epoch 399/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1233 - accuracy: 0.9586\n","Epoch 400/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1147 - accuracy: 0.9628\n","Epoch 401/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1214 - accuracy: 0.9597\n","Epoch 402/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1174 - accuracy: 0.9554\n","Epoch 403/500\n","30/30 [==============================] - 2s 71ms/step - loss: 0.1320 - accuracy: 0.9575\n","Epoch 404/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3059 - accuracy: 0.9045\n","Epoch 405/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1368 - accuracy: 0.9544\n","Epoch 406/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1383 - accuracy: 0.9544\n","Epoch 407/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1257 - accuracy: 0.9607\n","Epoch 408/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1397 - accuracy: 0.9522\n","Epoch 409/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1331 - accuracy: 0.9544\n","Epoch 410/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1192 - accuracy: 0.9575\n","Epoch 411/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0934 - accuracy: 0.9735\n","Epoch 412/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1210 - accuracy: 0.9544\n","Epoch 413/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.1189 - accuracy: 0.9565\n","Epoch 414/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0899 - accuracy: 0.9724\n","Epoch 415/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.1243 - accuracy: 0.9639\n","Epoch 416/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.1367 - accuracy: 0.9533\n","Epoch 417/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1177 - accuracy: 0.9628\n","Epoch 418/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0983 - accuracy: 0.9713\n","Epoch 419/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1344 - accuracy: 0.9650\n","Epoch 420/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2902 - accuracy: 0.9214\n","Epoch 421/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.0983 - accuracy: 0.9671\n","Epoch 422/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.2092 - accuracy: 0.9406\n","Epoch 423/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.2861 - accuracy: 0.9161\n","Epoch 424/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.2246 - accuracy: 0.9172\n","Epoch 425/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.0858 - accuracy: 0.9756\n","Epoch 426/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1283 - accuracy: 0.9639\n","Epoch 427/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.0989 - accuracy: 0.9713\n","Epoch 428/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0946 - accuracy: 0.9682\n","Epoch 429/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1382 - accuracy: 0.9565\n","Epoch 430/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.1308 - accuracy: 0.9607\n","Epoch 431/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0979 - accuracy: 0.9660\n","Epoch 432/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0993 - accuracy: 0.9724\n","Epoch 433/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0961 - accuracy: 0.9671\n","Epoch 434/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0650 - accuracy: 0.9788\n","Epoch 435/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1155 - accuracy: 0.9597\n","Epoch 436/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0847 - accuracy: 0.9766\n","Epoch 437/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.1072 - accuracy: 0.9692\n","Epoch 438/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0825 - accuracy: 0.9724\n","Epoch 439/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0945 - accuracy: 0.9735\n","Epoch 440/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0799 - accuracy: 0.9713\n","Epoch 441/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1207 - accuracy: 0.9628\n","Epoch 442/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0825 - accuracy: 0.9745\n","Epoch 443/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.1271 - accuracy: 0.9575\n","Epoch 444/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0699 - accuracy: 0.9766\n","Epoch 445/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0669 - accuracy: 0.9777\n","Epoch 446/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.0821 - accuracy: 0.9745\n","Epoch 447/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0986 - accuracy: 0.9628\n","Epoch 448/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.0859 - accuracy: 0.9703\n","Epoch 449/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.1667 - accuracy: 0.9597\n","Epoch 450/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1042 - accuracy: 0.9671\n","Epoch 451/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0699 - accuracy: 0.9766\n","Epoch 452/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0652 - accuracy: 0.9788\n","Epoch 453/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3109 - accuracy: 0.9299\n","Epoch 454/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.4739 - accuracy: 0.8758\n","Epoch 455/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1897 - accuracy: 0.9268\n","Epoch 456/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1794 - accuracy: 0.9342\n","Epoch 457/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.1024 - accuracy: 0.9628\n","Epoch 458/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0867 - accuracy: 0.9692\n","Epoch 459/500\n","30/30 [==============================] - 2s 69ms/step - loss: 0.0787 - accuracy: 0.9735\n","Epoch 460/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.1117 - accuracy: 0.9565\n","Epoch 461/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0974 - accuracy: 0.9703\n","Epoch 462/500\n","30/30 [==============================] - 2s 70ms/step - loss: 0.0628 - accuracy: 0.9798\n","Epoch 463/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0901 - accuracy: 0.9703\n","Epoch 464/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0916 - accuracy: 0.9703\n","Epoch 465/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0685 - accuracy: 0.9777\n","Epoch 466/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0597 - accuracy: 0.9862\n","Epoch 467/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.0994 - accuracy: 0.9692\n","Epoch 468/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0538 - accuracy: 0.9841\n","Epoch 469/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.9143 - accuracy: 0.8355\n","Epoch 470/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.5352 - accuracy: 0.8694\n","Epoch 471/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.6424 - accuracy: 0.8535\n","Epoch 472/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.2649 - accuracy: 0.9214\n","Epoch 473/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.3108 - accuracy: 0.9013\n","Epoch 474/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0813 - accuracy: 0.9735\n","Epoch 475/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.1272 - accuracy: 0.9597\n","Epoch 476/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0623 - accuracy: 0.9841\n","Epoch 477/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0685 - accuracy: 0.9756\n","Epoch 478/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.1761 - accuracy: 0.9522\n","Epoch 479/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.0637 - accuracy: 0.9777\n","Epoch 480/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.0804 - accuracy: 0.9766\n","Epoch 481/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.2083 - accuracy: 0.9544\n","Epoch 482/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.1710 - accuracy: 0.9512\n","Epoch 483/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0596 - accuracy: 0.9830\n","Epoch 484/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0665 - accuracy: 0.9766\n","Epoch 485/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0670 - accuracy: 0.9809\n","Epoch 486/500\n","30/30 [==============================] - 2s 64ms/step - loss: 0.0721 - accuracy: 0.9798\n","Epoch 487/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0529 - accuracy: 0.9894\n","Epoch 488/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.0406 - accuracy: 0.9904\n","Epoch 489/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.1171 - accuracy: 0.9565\n","Epoch 490/500\n","30/30 [==============================] - 2s 67ms/step - loss: 0.0520 - accuracy: 0.9851\n","Epoch 491/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0796 - accuracy: 0.9809\n","Epoch 492/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.0815 - accuracy: 0.9756\n","Epoch 493/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.0662 - accuracy: 0.9788\n","Epoch 494/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.0429 - accuracy: 0.9862\n","Epoch 495/500\n","30/30 [==============================] - 2s 63ms/step - loss: 0.1133 - accuracy: 0.9713\n","Epoch 496/500\n","30/30 [==============================] - 2s 62ms/step - loss: 0.1052 - accuracy: 0.9660\n","Epoch 497/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.0430 - accuracy: 0.9883\n","Epoch 498/500\n","30/30 [==============================] - 2s 68ms/step - loss: 0.0256 - accuracy: 0.9958\n","Epoch 499/500\n","30/30 [==============================] - 2s 66ms/step - loss: 0.0963 - accuracy: 0.9703\n","Epoch 500/500\n","30/30 [==============================] - 2s 65ms/step - loss: 0.0696 - accuracy: 0.9841\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VqGINkQK6ckf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600817450746,"user_tz":240,"elapsed":2167,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["pred = model.predict(test1)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"ly2APd3_9ovT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600817451967,"user_tz":240,"elapsed":415,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"ccf029fe-da93-40a4-e43c-0eec1f33c4a9"},"source":["np.argmax(pred[1])"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"5u4qnWZM8XOd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600817453523,"user_tz":240,"elapsed":551,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["predLabel = np.empty([len(test),2],dtype=int)\n","for i in range(len(pred)):\n","  predLabel[i][0] = np.int(i)\n","  predLabel[i][1] = np.int(np.argmax(pred[i]))\n"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJ6LunBh90oB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600817459963,"user_tz":240,"elapsed":490,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}}},"source":["df = pd.DataFrame(predLabel, columns= ['id', 'label'])\n","\n","df.to_csv (r'haiqzhu5.csv', index = False, header=True)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFdJIUfj90iZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1599690510095,"user_tz":240,"elapsed":267,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"12057532-4bc4-4777-9f53-d289fe556d3e"},"source":["sample_submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>553</th>\n","      <td>553</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>554</th>\n","      <td>554</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>555</th>\n","      <td>555</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>556</th>\n","      <td>556</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>557</th>\n","      <td>557</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>558 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      id  label\n","0      0      1\n","1      1      6\n","2      2      3\n","3      3      7\n","4      4      4\n","..   ...    ...\n","553  553      6\n","554  554      0\n","555  555      2\n","556  556      9\n","557  557      6\n","\n","[558 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":204}]},{"cell_type":"code","metadata":{"id":"oKntMnZJ_vQF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1599690955305,"user_tz":240,"elapsed":293,"user":{"displayName":"Haiqi Zhu","photoUrl":"","userId":"00612599187227358197"}},"outputId":"73bc57b9-d2e2-413a-ce9e-fa80b34e8f9b"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>553</th>\n","      <td>553</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>554</th>\n","      <td>554</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>555</th>\n","      <td>555</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>556</th>\n","      <td>556</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>557</th>\n","      <td>557</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>558 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      id  label\n","0      0      5\n","1      1      9\n","2      2      4\n","3      3      1\n","4      4      4\n","..   ...    ...\n","553  553      1\n","554  554      5\n","555  555      5\n","556  556      7\n","557  557      5\n","\n","[558 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":217}]}]}